---
title: 多项式回归
categories: 机器学习
comments: true
mathjax: true
tags:
  - 回归
  - Scikit-Learn
abbrlink: 9768
date: 2018-02-14 10:22:54
---

研究一个因变量与一个或多个自变量间多项式的回归分析方法，称为多项式回归（Polynomial Regression）。多项式回归可以用来解决非线性的数据。

<!--more-->

## 输入数据

```python
m=100
x = 6 * np.random.rand(m, 1) - 3
y = 0.5 * x**2 + x + 2 + np.random.randn(m, 1)
```

![polynomial-regression-input](polynomial-regression-input.svg)

输入的数据为：

$$
y = 0.5x^2 + 1.0x + 2.0 + noise
$$

## 处理

通过输入数据的示意图，显然不能用一条直线就可以把它表示清楚。需要先把特征的平方或者更高维特征添加进模型，以作为模型的新特征。在这里使用 `PolynomialFeatures` 添加特征的平方作为新特征。

```python
from sklearn.preprocessing import PolynomialFeatures
poly_features = PolynomialFeatures(degree=2, include_bias=False)
x_poly = poly_features.fit_transform(x)
```

这时候 `x_poly` 就包含了 `x` 的平方这个特征。然后就可以使用[线性回归](/posts/52662/)来训练模型。

```python
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(x_poly, y)
lin_reg.intercept_, lin_reg.coef_
#output: (array([ 1.92814908]), array([[ 0.96860925,  0.49263447]]))
```

预测的模型的表达式为：

$$
y = 0.49263447x^2 + 0.96860925x + 1.92814908
$$

![polynomial-regression-prediction](polynomial-regression-prediction.svg)

## 小结

多项式回归（Polynomial Regression）相比线性回归，它可以利用到不同特征之间的关系。比如如果有两个特征 $a$ 和 $b$ ，`PolynomialFeatures` 方法（degree=3）会把特征 $a^2$ 、$a^3$ 、$b^2$ 、$b^3$ 以及 $ab$ 、$a^2b$ 和 $ab^2$ 加入模型的训练中。 